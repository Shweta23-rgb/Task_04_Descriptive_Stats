{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "51eaba62-2659-408d-a62c-adf9b51531e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a4cfa32-fb51-4f8d-ac70-9495813455bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "facebook_ads = pd.read_csv(\"2024_fb_ads_president_scored_anon.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f59f1d3d-6931-4e3f-a883-85b5096a54ad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== FINDING DICTIONARY COLUMNS ===\n",
      "Object columns to check: ['page_id', 'ad_id', 'ad_creation_time', 'bylines', 'currency', 'delivery_by_region', 'demographic_distribution', 'publisher_platforms', 'illuminating_scored_message', 'illuminating_mentions']\n",
      "\n",
      "Checking each object column for complex data structures:\n",
      "\n",
      "--- page_id ---\n",
      "Sample 1: 4ff23a48b53d988df50ddfebb0e442a984ab8f94e874ef9b9cb34394e0c5d230...\n",
      "Type: str\n",
      "  Regular string\n",
      "Sample 2: 4ff23a48b53d988df50ddfebb0e442a984ab8f94e874ef9b9cb34394e0c5d230...\n",
      "Type: str\n",
      "  Regular string\n",
      "Sample 3: 4ff23a48b53d988df50ddfebb0e442a984ab8f94e874ef9b9cb34394e0c5d230...\n",
      "Type: str\n",
      "  Regular string\n",
      "  Just regular strings\n",
      "\n",
      "--- ad_id ---\n",
      "Sample 1: 0ddb025b8544e2d58e6977ad417e742a52522b3e1fc1c9d9b61c57148f8d72fc...\n",
      "Type: str\n",
      "  Regular string\n",
      "Sample 2: 86229868e6bde3661724fe02da93504bb4fb5da8c2550d7b7cf193c687e89fa6...\n",
      "Type: str\n",
      "  Regular string\n",
      "Sample 3: 07b5aefc27e872e971f793e49aac38496fa62e484f3928e2b6a2b6e3e08cac8d...\n",
      "Type: str\n",
      "  Regular string\n",
      "  Just regular strings\n",
      "\n",
      "--- ad_creation_time ---\n",
      "Sample 1: 2024-10-21...\n",
      "Type: str\n",
      "  Regular string\n",
      "Sample 2: 2024-10-18...\n",
      "Type: str\n",
      "  Regular string\n",
      "Sample 3: 2024-10-13...\n",
      "Type: str\n",
      "  Regular string\n",
      "  Just regular strings\n",
      "\n",
      "--- bylines ---\n",
      "Sample 1: Texas Organizing Project PAC...\n",
      "Type: str\n",
      "  Regular string\n",
      "Sample 2: Texas Organizing Project PAC...\n",
      "Type: str\n",
      "  Regular string\n",
      "Sample 3: Texas Organizing Project PAC...\n",
      "Type: str\n",
      "  Regular string\n",
      "  Just regular strings\n",
      "\n",
      "--- currency ---\n",
      "Sample 1: USD...\n",
      "Type: str\n",
      "  Regular string\n",
      "Sample 2: USD...\n",
      "Type: str\n",
      "  Regular string\n",
      "Sample 3: USD...\n",
      "Type: str\n",
      "  Regular string\n",
      "  Just regular strings\n",
      "\n",
      "--- delivery_by_region ---\n",
      "Sample 1: {'Texas': {'spend': 249, 'impressions': 47499}}...\n",
      "Type: str\n",
      "  PYTHON DICT detected with keys: ['Texas']\n",
      "Sample 2: {'Texas': {'spend': 49, 'impressions': 22499}}...\n",
      "Type: str\n",
      "  PYTHON DICT detected with keys: ['Texas']\n",
      "Sample 3: {'Texas': {'spend': 149, 'impressions': 32499}}...\n",
      "Type: str\n",
      "  PYTHON DICT detected with keys: ['Texas']\n",
      "  CONTAINS DICTIONARIES\n",
      "\n",
      "--- demographic_distribution ---\n",
      "Sample 1: {'female_18-24': {'spend': 28, 'impressions': 5507}, 'male_45-54': {'spend': 14, 'impressions': 2757...\n",
      "Type: str\n",
      "  PYTHON DICT detected with keys: ['female_18-24', 'male_45-54', 'male_65+', 'female_65+', 'unknown_55-64', 'male_55-64', 'female_55-64', 'unknown_45-54', 'female_45-54', 'male_18-24', 'unknown_35-44', 'male_35-44', 'female_35-44', 'unknown_25-34', 'male_25-34', 'female_25-34', 'unknown_18-24', 'unknown_65+']\n",
      "Sample 2: {'female_18-24': {'spend': 8, 'impressions': 3904}, 'male_45-54': {'spend': 2, 'impressions': 1129},...\n",
      "Type: str\n",
      "  PYTHON DICT detected with keys: ['female_18-24', 'male_45-54', 'male_65+', 'female_65+', 'unknown_55-64', 'male_55-64', 'female_55-64', 'unknown_45-54', 'female_45-54', 'male_18-24', 'unknown_35-44', 'male_35-44', 'female_35-44', 'unknown_25-34', 'male_25-34', 'female_25-34', 'unknown_18-24', 'unknown_65+']\n",
      "Sample 3: {'female_18-24': {'spend': 26, 'impressions': 5791}, 'male_45-54': {'spend': 7, 'impressions': 1573}...\n",
      "Type: str\n",
      "  PYTHON DICT detected with keys: ['female_18-24', 'male_45-54', 'male_65+', 'female_65+', 'unknown_55-64', 'male_55-64', 'female_55-64', 'unknown_45-54', 'female_45-54', 'male_18-24', 'unknown_35-44', 'male_35-44', 'female_35-44', 'unknown_25-34', 'male_25-34', 'female_25-34', 'unknown_18-24', 'unknown_65+']\n",
      "  CONTAINS DICTIONARIES\n",
      "\n",
      "--- publisher_platforms ---\n",
      "Sample 1: ['facebook', 'instagram']...\n",
      "Type: str\n",
      "  PYTHON LIST detected with 2 items\n",
      "Sample 2: ['facebook', 'instagram']...\n",
      "Type: str\n",
      "  PYTHON LIST detected with 2 items\n",
      "Sample 3: ['facebook', 'instagram']...\n",
      "Type: str\n",
      "  PYTHON LIST detected with 2 items\n",
      "  CONTAINS LISTS\n",
      "\n",
      "--- illuminating_scored_message ---\n",
      "Sample 1: 362d68d42e34e070bc9f999033642b8fddfca5404195fc27690c60e0acde1d5b...\n",
      "Type: str\n",
      "  Regular string\n",
      "Sample 2: dc522d5aa4f91c326d105ec4c482cf4b0c378161a6438a4c604061979c49f0dc...\n",
      "Type: str\n",
      "  Regular string\n",
      "Sample 3: 6dc61896f4a44cf4fdbe564604bbebe33b84d2dbfb8bacc761b345b2879f0804...\n",
      "Type: str\n",
      "  Regular string\n",
      "  Just regular strings\n",
      "\n",
      "--- illuminating_mentions ---\n",
      "Sample 1: ['Kamala Harris', 'Tim Walz']...\n",
      "Type: str\n",
      "  PYTHON LIST detected with 2 items\n",
      "Sample 2: ['Kamala Harris', 'Tim Walz']...\n",
      "Type: str\n",
      "  PYTHON LIST detected with 2 items\n",
      "Sample 3: ['Kamala Harris', 'Tim Walz']...\n",
      "Type: str\n",
      "  PYTHON LIST detected with 2 items\n",
      "  CONTAINS LISTS\n",
      "\n",
      "==================================================\n",
      "SUMMARY\n",
      "==================================================\n",
      "Dictionary columns: ['delivery_by_region', 'demographic_distribution']\n",
      "List columns: ['publisher_platforms', 'illuminating_mentions']\n",
      "Simple string columns: ['page_id', 'ad_id', 'ad_creation_time', 'bylines', 'currency', 'illuminating_scored_message']\n",
      "\n",
      "Total complex columns to handle: 4\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import ast\n",
    "\n",
    "# Script to find dictionary/JSON columns in Facebook Ads dataset\n",
    "print(\"=== FINDING DICTIONARY COLUMNS ===\")\n",
    "\n",
    "# Get all object columns\n",
    "object_columns = facebook_ads.select_dtypes(include=['object']).columns\n",
    "print(f\"Object columns to check: {list(object_columns)}\")\n",
    "\n",
    "def check_for_dictionaries(df, column):\n",
    "    \"\"\"Check if a column contains dictionaries or JSON structures\"\"\"\n",
    "    print(f\"\\n--- {column} ---\")\n",
    "    \n",
    "    # Get first 3 non-null values\n",
    "    sample_values = df[column].dropna().head(3).tolist()\n",
    "    \n",
    "    has_dicts = False\n",
    "    has_lists = False\n",
    "    \n",
    "    for i, val in enumerate(sample_values):\n",
    "        print(f\"Sample {i+1}: {str(val)[:100]}...\")\n",
    "        print(f\"Type: {type(val).__name__}\")\n",
    "        \n",
    "        if isinstance(val, str):\n",
    "            # Check if it looks like JSON\n",
    "            if val.strip().startswith('{'):\n",
    "                try:\n",
    "                    parsed = json.loads(val)\n",
    "                    if isinstance(parsed, dict):\n",
    "                        has_dicts = True\n",
    "                        print(f\"  DICTIONARY detected with keys: {list(parsed.keys())}\")\n",
    "                except:\n",
    "                    try:\n",
    "                        parsed = ast.literal_eval(val)\n",
    "                        if isinstance(parsed, dict):\n",
    "                            has_dicts = True\n",
    "                            print(f\"  PYTHON DICT detected with keys: {list(parsed.keys())}\")\n",
    "                    except:\n",
    "                        print(\"  Looks like dict but can't parse\")\n",
    "            elif val.strip().startswith('['):\n",
    "                try:\n",
    "                    parsed = json.loads(val)\n",
    "                    if isinstance(parsed, list):\n",
    "                        has_lists = True\n",
    "                        print(f\"  LIST detected with {len(parsed)} items\")\n",
    "                except:\n",
    "                    try:\n",
    "                        parsed = ast.literal_eval(val)\n",
    "                        if isinstance(parsed, list):\n",
    "                            has_lists = True\n",
    "                            print(f\"  PYTHON LIST detected with {len(parsed)} items\")\n",
    "                    except:\n",
    "                        print(\"  Looks like list but can't parse\")\n",
    "            else:\n",
    "                print(\"  Regular string\")\n",
    "    \n",
    "    if has_dicts:\n",
    "        print(\"  CONTAINS DICTIONARIES\")\n",
    "        return \"DICTIONARY\"\n",
    "    elif has_lists:\n",
    "        print(\"  CONTAINS LISTS\")\n",
    "        return \"LIST\"\n",
    "    else:\n",
    "        print(\"  Just regular strings\")\n",
    "        return \"STRING\"\n",
    "\n",
    "# Check each object column\n",
    "print(\"\\nChecking each object column for complex data structures:\")\n",
    "\n",
    "results = {}\n",
    "for col in object_columns:\n",
    "    result = check_for_dictionaries(facebook_ads, col)\n",
    "    results[col] = result\n",
    "\n",
    "# Summary\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "dict_columns = [k for k, v in results.items() if v == \"DICTIONARY\"]\n",
    "list_columns = [k for k, v in results.items() if v == \"LIST\"]\n",
    "string_columns = [k for k, v in results.items() if v == \"STRING\"]\n",
    "\n",
    "print(f\"Dictionary columns: {dict_columns}\")\n",
    "print(f\"List columns: {list_columns}\")\n",
    "print(f\"Simple string columns: {string_columns}\")\n",
    "\n",
    "print(f\"\\nTotal complex columns to handle: {len(dict_columns) + len(list_columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9be06d9-310b-4eb2-96cf-759555ee1c7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# After running your detection script...\n",
    "dict_columns = ['delivery_by_region', 'demographic_distribution']\n",
    "list_columns = ['publisher_platforms', 'illuminating_mentions']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da00cd9-482e-426d-ae2e-ab2c12672627",
   "metadata": {},
   "source": [
    "The below code is designed to convert columns that contain stringified (text) representations of Python dictionaries or lists into real, usable Python objects in the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35664b33-884c-475b-9e7b-fde953d8e371",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import ast\n",
    "\n",
    "def safe_parse(val):\n",
    "    \"\"\"Convert a stringified dict/list to real Python object, or leave as-is if not possible.\"\"\"\n",
    "    if isinstance(val, str) and val.strip() and (val.strip().startswith(\"{\") or val.strip().startswith(\"[\")):\n",
    "        try:\n",
    "            return json.loads(val)\n",
    "        except Exception:\n",
    "            try:\n",
    "                return ast.literal_eval(val)\n",
    "            except Exception:\n",
    "                return val  # return original if can't parse\n",
    "    else:\n",
    "        return val\n",
    "\n",
    "for col in dict_columns + list_columns:\n",
    "    facebook_ads[col] = facebook_ads[col].apply(safe_parse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9def12a-c279-4aee-a0a1-220037b9f454",
   "metadata": {},
   "source": [
    "I am trying to unpack the delivery_by_region dictionary column so that each (ad, region) combination becomes its own row, with associated spend and impressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7eed95d-82ba-42b3-8833-9f01e12d7ca0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "delivery_rows = []\n",
    "for idx, row in facebook_ads.iterrows():\n",
    "    ad_id = row['ad_id']\n",
    "    d = row['delivery_by_region']\n",
    "    if isinstance(d, dict):\n",
    "        for region, vals in d.items():\n",
    "            delivery_rows.append({\n",
    "                'ad_id': ad_id,\n",
    "                'region': region,\n",
    "                'spend': vals.get('spend'),\n",
    "                'impressions': vals.get('impressions')\n",
    "            })\n",
    "delivery_df = pd.DataFrame(delivery_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5529fffb-c920-4818-8b25-06d535703828",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "demo_rows = []\n",
    "for idx, row in facebook_ads.iterrows():\n",
    "    ad_id = row['ad_id']\n",
    "    d = row['demographic_distribution']\n",
    "    if isinstance(d, dict):\n",
    "        for group, vals in d.items():\n",
    "            demo_rows.append({\n",
    "                'ad_id': ad_id,\n",
    "                'group': group,\n",
    "                'spend': vals.get('spend'),\n",
    "                'impressions': vals.get('impressions')\n",
    "            })\n",
    "demo_df = pd.DataFrame(demo_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bca0f6ab-ac25-4ea9-9052-688afe76b84b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "facebook_ads['publisher_platforms'] = facebook_ads['publisher_platforms'].apply(\n",
    "    lambda x: x if isinstance(x, list) else []\n",
    ")\n",
    "platform_df = facebook_ads[['ad_id', 'publisher_platforms']].explode('publisher_platforms').rename(\n",
    "    columns={'publisher_platforms': 'platform'}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f0b954a-7a9d-4dc6-9b37-ebffab8fd463",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "facebook_ads['illuminating_mentions'] = facebook_ads['illuminating_mentions'].apply(\n",
    "    lambda x: x if isinstance(x, list) else []\n",
    ")\n",
    "mentions_df = facebook_ads[['ad_id', 'illuminating_mentions']].explode('illuminating_mentions').rename(\n",
    "    columns={'illuminating_mentions': 'mention'}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6fd62b-be09-4c92-9db4-3903e67ebe27",
   "metadata": {},
   "source": [
    "I analysed all the complex \"dict/list\" columns seperately? \n",
    "\n",
    "**Why Analyze Exploded DataFrames Separately?**\n",
    "\n",
    "The original facebook_ads DataFrame has one row per ad, but columns like delivery_by_region, demographic_distribution, publisher_platforms, and illuminating_mentions are lists or dictionaries that capture multiple regions, demographics, platforms, or mentions per ad.\n",
    "\n",
    "When we “explode” (unpack) these columns, we create new DataFrames where each row is one (ad, subitem) combination—e.g., one region within an ad.\n",
    "\n",
    "These exploded DataFrames don’t align row-by-row with the original ads. That’s why we analyze them separately—grouping, summarizing, or visualizing their structure is most meaningful on their own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33e0829f-4545-4106-bb90-e83d08c54e20",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Delivery by Region: Spend & Impressions ===\n",
      "                                     spend                                     \\\n",
      "                                     count        mean          std  min  25%   \n",
      "region                                                                          \n",
      "Alabama                           105247.0   13.342072    84.308521  0.0  0.0   \n",
      "Alaska                             96215.0    6.139313    78.537885  0.0  0.0   \n",
      "Arizona                           122331.0   97.405637   695.468544  0.0  1.0   \n",
      "Arkansas                          102892.0   10.137533    93.058208  0.0  0.0   \n",
      "California                        110936.0  176.665005  1047.200365  0.0  4.0   \n",
      "Colorado                          107790.0   31.158373   169.197975  0.0  0.0   \n",
      "Connecticut                       105438.0   18.534826    98.279632  0.0  0.0   \n",
      "Delaware                           97511.0    6.065080    33.541108  0.0  0.0   \n",
      "Florida                           111351.0   87.892170   531.086289  0.0  3.0   \n",
      "Georgia                           123216.0  132.251031  1022.672361  0.0  1.0   \n",
      "Hawaii                             95166.0    5.810594    31.325164  0.0  0.0   \n",
      "Idaho                             100568.0    7.901519    52.418969  0.0  0.0   \n",
      "Illinois                          109731.0   47.771487   237.958480  0.0  1.0   \n",
      "Indiana                           108535.0   23.803087   160.859423  0.0  0.0   \n",
      "Iowa                              107544.0   22.526863   303.644386  0.0  0.0   \n",
      "Kansas                            105248.0   11.329983    63.012593  0.0  0.0   \n",
      "Kentucky                          106061.0   15.000321   109.298343  0.0  0.0   \n",
      "Louisiana                         103453.0   11.932037    84.610512  0.0  0.0   \n",
      "Maine                             104639.0   12.466088   100.525721  0.0  0.0   \n",
      "Maryland                          108091.0   30.013535   168.235614  0.0  0.0   \n",
      "Massachusetts                     107578.0   41.588884   254.511268  0.0  1.0   \n",
      "Michigan                          124399.0  212.754845  1801.246954  0.0  1.0   \n",
      "Minnesota                         108485.0   31.889459   193.426940  0.0  0.0   \n",
      "Mississippi                        98304.0    6.713450    53.371905  0.0  0.0   \n",
      "Missouri                          108492.0   24.318005   158.366869  0.0  0.0   \n",
      "Montana                            98510.0   10.498315   279.048408  0.0  0.0   \n",
      "Nebraska                          105050.0   14.256525   159.016128  0.0  0.0   \n",
      "Nevada                            116653.0   66.137373   519.764249  0.0  0.0   \n",
      "New Hampshire                     104959.0   27.375823   322.339495  0.0  0.0   \n",
      "New Jersey                        109672.0   38.097491   196.912633  0.0  1.0   \n",
      "New Mexico                        103051.0   10.297658    57.978120  0.0  0.0   \n",
      "New York                          111365.0   99.451785   532.835365  0.0  2.0   \n",
      "North Carolina                    123519.0  141.462981  1048.720291  0.0  1.0   \n",
      "North Dakota                       90044.0    2.705844    23.024410  0.0  0.0   \n",
      "Ohio                              111158.0   50.208451   357.630613  0.0  1.0   \n",
      "Oklahoma                          104992.0   12.829749   101.558308  0.0  0.0   \n",
      "Oregon                            106456.0   27.995641   149.745225  0.0  0.0   \n",
      "Pennsylvania                      127280.0  244.560339  1880.063659  0.0  2.0   \n",
      "Rhode Island                       96615.0    6.189308    41.012567  0.0  0.0   \n",
      "South Carolina                    108273.0   27.671100   392.404237  0.0  0.0   \n",
      "South Dakota                       92471.0    3.265705    26.583477  0.0  0.0   \n",
      "Tennessee                         108931.0   27.617529   265.035454  0.0  0.0   \n",
      "Texas                             112132.0   89.095272   679.983585  0.0  2.0   \n",
      "Utah                              102460.0   11.306949    96.100262  0.0  0.0   \n",
      "Vermont                            94445.0    5.961396    33.042115  0.0  0.0   \n",
      "Virginia                          110166.0   42.855255   291.504331  0.0  1.0   \n",
      "Washington                        107889.0   46.131941   243.514388  0.0  1.0   \n",
      "Washington, District of Columbia   84201.0   12.518687    89.790942  0.0  0.0   \n",
      "West Virginia                     101116.0    7.169845    82.197827  0.0  0.0   \n",
      "Wisconsin                         122128.0  121.667455  1023.979914  0.0  0.0   \n",
      "Wyoming                            87976.0    2.812062    23.335084  0.0  0.0   \n",
      "\n",
      "                                                      impressions  \\\n",
      "                                  50%   75%       max       count   \n",
      "region                                                              \n",
      "Alabama                           1.0   4.0    7861.0    105247.0   \n",
      "Alaska                            0.0   1.0   12498.0     96215.0   \n",
      "Arizona                           3.0  20.0   54999.0    122331.0   \n",
      "Arkansas                          0.0   3.0   12499.0    102892.0   \n",
      "California                        8.0  49.0   94728.0    110936.0   \n",
      "Colorado                          1.0   9.0   12498.0    107790.0   \n",
      "Connecticut                       1.0   5.0    4988.0    105438.0   \n",
      "Delaware                          0.0   2.0    2429.0     97511.0   \n",
      "Florida                           5.0  31.0   74998.0    111351.0   \n",
      "Georgia                           3.0  23.0   84999.0    123216.0   \n",
      "Hawaii                            0.0   2.0    1890.0     95166.0   \n",
      "Idaho                             0.0   2.0    7468.0    100568.0   \n",
      "Illinois                          2.0  16.0   14825.0    109731.0   \n",
      "Indiana                           1.0   8.0   27497.0    108535.0   \n",
      "Iowa                              1.0   5.0   32498.0    107544.0   \n",
      "Kansas                            0.0   4.0    6161.0    105248.0   \n",
      "Kentucky                          1.0   5.0   22498.0    106061.0   \n",
      "Louisiana                         0.0   3.0   12499.0    103453.0   \n",
      "Maine                             0.0   3.0   17498.0    104639.0   \n",
      "Maryland                          1.0   8.0    7675.0    108091.0   \n",
      "Massachusetts                     2.0  12.0   32448.0    107578.0   \n",
      "Michigan                          4.0  29.0  137497.0    124399.0   \n",
      "Minnesota                         1.0  10.0   17499.0    108485.0   \n",
      "Mississippi                       0.0   2.0    6498.0     98304.0   \n",
      "Missouri                          1.0   8.0   17497.0    108492.0   \n",
      "Montana                           0.0   2.0   74994.0     98510.0   \n",
      "Nebraska                          0.0   3.0   23902.0    105050.0   \n",
      "Nevada                            1.0   7.0   41536.0    116653.0   \n",
      "New Hampshire                     0.0   3.0   27498.0    104959.0   \n",
      "New Jersey                        2.0  12.0   10714.0    109672.0   \n",
      "New Mexico                        0.0   3.0    4749.0    103051.0   \n",
      "New York                          4.0  29.0   26360.0    111365.0   \n",
      "North Carolina                    4.0  27.0   74999.0    123519.0   \n",
      "North Dakota                      0.0   1.0    3248.0     90044.0   \n",
      "Ohio                              2.0  15.0   54999.0    111158.0   \n",
      "Oklahoma                          1.0   4.0   12498.0    104992.0   \n",
      "Oregon                            1.0   9.0   12498.0    106456.0   \n",
      "Pennsylvania                      6.0  45.0  162496.0    127280.0   \n",
      "Rhode Island                      0.0   2.0    5499.0     96615.0   \n",
      "South Carolina                    1.0   6.0   37499.0    108273.0   \n",
      "South Dakota                      0.0   1.0    4749.0     92471.0   \n",
      "Tennessee                         1.0   8.0   37499.0    108931.0   \n",
      "Texas                             5.0  28.0  162489.0    112132.0   \n",
      "Utah                              0.0   3.0   12476.0    102460.0   \n",
      "Vermont                           0.0   2.0    1874.0     94445.0   \n",
      "Virginia                          2.0  12.0   32499.0    110166.0   \n",
      "Washington                        2.0  14.0   13896.0    107889.0   \n",
      "Washington, District of Columbia  0.0   2.0    4748.0     84201.0   \n",
      "West Virginia                     0.0   2.0   17499.0    101116.0   \n",
      "Wisconsin                         2.0  17.0   94998.0    122128.0   \n",
      "Wyoming                           0.0   1.0    2748.0     87976.0   \n",
      "\n",
      "                                                                         \\\n",
      "                                          mean           std  min   25%   \n",
      "region                                                                    \n",
      "Alabama                             618.703906   3061.119619  0.0  10.0   \n",
      "Alaska                              307.023967   6088.651960  0.0   4.0   \n",
      "Arizona                            5033.959430  35550.011666  0.0  22.0   \n",
      "Arkansas                            515.902266   6718.622668  0.0   7.0   \n",
      "California                         5151.000288  20883.474900  0.0  79.0   \n",
      "Colorado                           1021.938380   4705.063307  0.0  16.0   \n",
      "Connecticut                         584.754263   2559.206317  0.0  10.0   \n",
      "Delaware                            213.584447   1995.186340  0.0   5.0   \n",
      "Florida                            3410.302404  18228.036804  0.0  50.0   \n",
      "Georgia                            6874.507572  47674.859946  0.0  23.0   \n",
      "Hawaii                              200.374241   2033.542439  0.0   5.0   \n",
      "Idaho                               327.355769   2533.921132  0.0   6.0   \n",
      "Illinois                           1650.918820   5706.396698  0.0  25.0   \n",
      "Indiana                            1022.471415   7953.236224  0.0  16.0   \n",
      "Iowa                               1054.166332  14869.313461  0.0   9.0   \n",
      "Kansas                              495.676279   4761.330746  0.0   8.0   \n",
      "Kentucky                            660.752982   3970.848333  0.0  11.0   \n",
      "Louisiana                           561.852474   4949.783551  0.0   8.0   \n",
      "Maine                               458.420952   4338.127646  0.0   7.0   \n",
      "Maryland                            968.389838   6042.766033  0.0  14.0   \n",
      "Massachusetts                      1220.975125   5998.781600  0.0  20.0   \n",
      "Michigan                          10478.383154  66903.531603  0.0  31.0   \n",
      "Minnesota                          1241.524423   8902.311113  0.0  16.0   \n",
      "Mississippi                         351.913788   3840.946972  0.0   5.0   \n",
      "Missouri                           1066.943609   8869.304412  0.0  15.0   \n",
      "Montana                             537.409380  11584.399802  0.0   5.0   \n",
      "Nebraska                            725.294355   8417.440655  0.0   6.0   \n",
      "Nevada                             3566.601905  28152.119337  0.0  10.0   \n",
      "New Hampshire                      1220.222554  15045.289982  0.0   6.0   \n",
      "New Jersey                         1285.889170   6542.974964  0.0  20.0   \n",
      "New Mexico                          387.328197   3922.310133  0.0   8.0   \n",
      "New York                           3156.770296  15338.074268  0.0  45.0   \n",
      "North Carolina                     7200.317635  47254.434900  0.0  30.0   \n",
      "North Dakota                        137.915208   1414.659448  0.0   3.0   \n",
      "Ohio                               2208.427841  17741.882616  0.0  26.0   \n",
      "Oklahoma                            582.777364   5104.430752  0.0   9.0   \n",
      "Oregon                              902.523334   4065.728001  0.0  16.0   \n",
      "Pennsylvania                      11742.052899  69380.143637  0.0  44.0   \n",
      "Rhode Island                        212.945743   2256.541972  0.0   5.0   \n",
      "South Carolina                     1184.413252  15545.903649  0.0  12.0   \n",
      "South Dakota                        161.914038   2305.607406  0.0   4.0   \n",
      "Tennessee                          1231.727681  11721.897558  0.0  16.0   \n",
      "Texas                              3427.076981  17261.081458  0.0  45.0   \n",
      "Utah                                454.964367   5756.023730  0.0   7.0   \n",
      "Vermont                             188.618476    691.313844  0.0   4.0   \n",
      "Virginia                           1538.064140  11578.494360  0.0  20.0   \n",
      "Washington                         1423.336160   5654.364002  0.0  24.0   \n",
      "Washington, District of Columbia    401.136008   6197.095202  0.0   4.0   \n",
      "West Virginia                       369.975691   4849.375198  0.0   6.0   \n",
      "Wisconsin                          6600.918602  48367.211579  0.0  19.0   \n",
      "Wyoming                             145.791045   1887.715217  0.0   3.0   \n",
      "\n",
      "                                                            \n",
      "                                    50%     75%        max  \n",
      "region                                                      \n",
      "Alabama                            40.0   214.0   374999.0  \n",
      "Alaska                             17.0    86.0   849563.0  \n",
      "Arizona                           120.0   775.0  1000000.0  \n",
      "Arkansas                           31.0   160.0  1000000.0  \n",
      "California                        382.0  2165.0   999997.0  \n",
      "Colorado                           77.0   432.0   549991.0  \n",
      "Connecticut                        48.0   259.0   324973.0  \n",
      "Delaware                           20.0    98.0   324999.0  \n",
      "Florida                           255.0  1383.0  1000000.0  \n",
      "Georgia                           127.0   872.0  1000000.0  \n",
      "Hawaii                             19.0    94.0   474999.0  \n",
      "Idaho                              26.0   136.0   474845.0  \n",
      "Illinois                          131.0   718.0   324971.0  \n",
      "Indiana                            71.0   386.0   999983.0  \n",
      "Iowa                               43.0   241.0  1000000.0  \n",
      "Kansas                             37.0   195.0   849942.0  \n",
      "Kentucky                           48.0   257.0   849976.0  \n",
      "Louisiana                          34.0   185.0  1000000.0  \n",
      "Maine                              31.0   173.0   549999.0  \n",
      "Maryland                           68.0   384.0   949999.0  \n",
      "Massachusetts                      91.0   514.0   998435.0  \n",
      "Michigan                          167.0  1168.0  1000000.0  \n",
      "Minnesota                          80.0   457.0   999978.0  \n",
      "Mississippi                        21.0   108.0   949946.0  \n",
      "Missouri                           69.0   379.0   999989.0  \n",
      "Montana                            20.0   101.0   999936.0  \n",
      "Nebraska                           27.0   152.0   869231.0  \n",
      "Nevada                             48.0   357.0  1000000.0  \n",
      "New Hampshire                      28.0   166.0  1000000.0  \n",
      "New Jersey                         97.0   532.0   849980.0  \n",
      "New Mexico                         33.0   167.0   649999.0  \n",
      "New York                          224.0  1267.0   999999.0  \n",
      "North Carolina                    159.0  1096.0  1000000.0  \n",
      "North Dakota                       12.0    56.0   274988.0  \n",
      "Ohio                              130.0   718.0  1000000.0  \n",
      "Oklahoma                           39.0   206.0   848328.0  \n",
      "Oregon                             73.0   404.0   474960.0  \n",
      "Pennsylvania                      235.0  1592.0  1000000.0  \n",
      "Rhode Island                       19.0    95.0   549999.0  \n",
      "South Carolina                     51.0   284.0  1000000.0  \n",
      "South Dakota                       14.0    67.0   549999.0  \n",
      "Tennessee                          71.0   383.0  1000000.0  \n",
      "Texas                             230.0  1276.0  1000000.0  \n",
      "Utah                               30.0   160.0   998207.0  \n",
      "Vermont                            17.0    89.0    64986.0  \n",
      "Virginia                           99.0   549.0  1000000.0  \n",
      "Washington                        112.0   626.0   649969.0  \n",
      "Washington, District of Columbia   16.0    90.0   849951.0  \n",
      "West Virginia                      23.0   119.0   949999.0  \n",
      "Wisconsin                         101.0   706.0  1000000.0  \n",
      "Wyoming                            11.0    52.0   274996.0  \n"
     ]
    }
   ],
   "source": [
    "# Analyze spend and impressions by region\n",
    "delivery_region_stats = delivery_df.groupby(\"region\")[[\"spend\", \"impressions\"]].describe()\n",
    "print(\"=== Delivery by Region: Spend & Impressions ===\")\n",
    "print(delivery_region_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "99c400cd-1665-4b36-8d18-427d67233d72",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Demographic Distribution: Spend & Impressions ===\n",
      "                    spend                                                 \\\n",
      "                    count        mean          std  min  25%   50%   75%   \n",
      "group                                                                      \n",
      "female_13-17         73.0    0.095890     0.819288  0.0  0.0   0.0   0.0   \n",
      "female_18-24     171101.0   58.111846   333.876079  0.0  0.0   2.0  14.0   \n",
      "female_25-34     194891.0  105.672207   551.114122  0.0  1.0   6.0  31.0   \n",
      "female_35-44     196516.0  123.394299   604.872368  0.0  1.0   6.0  39.0   \n",
      "female_45-54     204423.0  113.538208   561.588600  0.0  2.0   7.0  40.0   \n",
      "female_55-64     198293.0  146.581932   751.500109  0.0  4.0  10.0  55.0   \n",
      "female_65+       196563.0  223.882603  1216.710992  0.0  7.0  18.0  80.0   \n",
      "female_Unknown        5.0    0.000000     0.000000  0.0  0.0   0.0   0.0   \n",
      "male_13-17          149.0    0.053691     0.503840  0.0  0.0   0.0   0.0   \n",
      "male_18-24       172141.0   39.721043   245.668510  0.0  0.0   2.0  11.0   \n",
      "male_25-34       194166.0   83.966348   399.367477  0.0  1.0   6.0  30.0   \n",
      "male_35-44       194863.0   94.383634   442.623001  0.0  2.0   6.0  36.0   \n",
      "male_45-54       201472.0   86.624131   445.290281  0.0  3.0   7.0  35.0   \n",
      "male_55-64       195316.0  104.322836   600.393433  0.0  4.0  10.0  43.0   \n",
      "male_65+         193479.0  135.275575   780.287891  0.0  5.0  13.0  52.0   \n",
      "male_Unknown          3.0    0.000000     0.000000  0.0  0.0   0.0   0.0   \n",
      "unknown_13-17        29.0    1.620690     8.727681  0.0  0.0   0.0   0.0   \n",
      "unknown_18-24    113365.0    2.135412    12.342194  0.0  0.0   0.0   0.0   \n",
      "unknown_25-34    144758.0    2.214220    11.657849  0.0  0.0   0.0   1.0   \n",
      "unknown_35-44    152867.0    2.688121    13.970364  0.0  0.0   0.0   1.0   \n",
      "unknown_45-54    159396.0    2.033878    11.519022  0.0  0.0   0.0   1.0   \n",
      "unknown_55-64    160479.0    2.379078    14.492118  0.0  0.0   0.0   1.0   \n",
      "unknown_65+      166103.0    3.753852    23.590151  0.0  0.0   0.0   1.0   \n",
      "unknown_Unknown     389.0    0.000000     0.000000  0.0  0.0   0.0   0.0   \n",
      "\n",
      "                          impressions                                         \\\n",
      "                      max       count         mean           std  min    25%   \n",
      "group                                                                          \n",
      "female_13-17          7.0        73.0     3.931507      7.042192  1.0    1.0   \n",
      "female_18-24      24090.0    171101.0  3611.488781  17296.679891  0.0   12.0   \n",
      "female_25-34      48779.0    194891.0  5565.747756  21824.907815  0.0   32.0   \n",
      "female_35-44      29898.0    196516.0  5479.518675  19499.185655  0.0   46.0   \n",
      "female_45-54      33965.0    204423.0  4413.378093  14442.881125  0.0   63.0   \n",
      "female_55-64      58347.0    198293.0  5253.774954  16598.723515  0.0  101.0   \n",
      "female_65+        77273.0    196563.0  7594.024481  25877.494307  0.0  172.0   \n",
      "female_Unknown        0.0         5.0     1.000000      0.000000  1.0    1.0   \n",
      "male_13-17            6.0       149.0     6.718121     10.124282  1.0    2.0   \n",
      "male_18-24        37499.0    172141.0  2549.605422  12932.928289  0.0   15.0   \n",
      "male_25-34        29322.0    194166.0  4765.705077  18221.015948  0.0   42.0   \n",
      "male_35-44        24768.0    194863.0  4587.939311  15727.410159  0.0   54.0   \n",
      "male_45-54        54502.0    201472.0  3873.872434  12622.304971  0.0   67.0   \n",
      "male_55-64        98558.0    195316.0  4422.916300  15072.334499  0.0   96.0   \n",
      "male_65+         112121.0    193479.0  5244.240827  18914.979256  0.0  125.0   \n",
      "male_Unknown          0.0         3.0     1.333333      0.577350  1.0    1.0   \n",
      "unknown_13-17        47.0        29.0   425.551724   2272.439102  0.0    1.0   \n",
      "unknown_18-24      1145.0    113365.0   143.285458    634.088690  0.0    2.0   \n",
      "unknown_25-34       583.0    144758.0   120.419321    414.156699  0.0    3.0   \n",
      "unknown_35-44       889.0    152867.0   121.084923    359.171143  0.0    3.0   \n",
      "unknown_45-54       853.0    159396.0    84.746964    239.230279  0.0    3.0   \n",
      "unknown_55-64      1447.0    160479.0    89.942902    267.524276  0.0    3.0   \n",
      "unknown_65+        1752.0    166103.0   128.647460    425.999486  0.0    4.0   \n",
      "unknown_Unknown       0.0       389.0     2.691517      3.110086  0.0    1.0   \n",
      "\n",
      "                                           \n",
      "                   50%     75%        max  \n",
      "group                                      \n",
      "female_13-17       2.0     3.0       52.0  \n",
      "female_18-24      77.0   708.0   557419.0  \n",
      "female_25-34     201.0  1688.0   673639.0  \n",
      "female_35-44     277.0  2050.0   414699.0  \n",
      "female_45-54     358.0  2078.0   511804.0  \n",
      "female_55-64     527.0  2687.0   420417.0  \n",
      "female_65+       770.0  3798.0  1000000.0  \n",
      "female_Unknown     1.0     1.0        1.0  \n",
      "male_13-17         3.0     7.0       74.0  \n",
      "male_18-24        84.0   612.0  1000000.0  \n",
      "male_25-34       239.0  1697.0   669448.0  \n",
      "male_35-44       312.0  1971.5   421497.0  \n",
      "male_45-54       354.0  1918.0   309781.0  \n",
      "male_55-64       457.0  2266.0   392316.0  \n",
      "male_65+         548.0  2614.0   749999.0  \n",
      "male_Unknown       1.0     1.5        2.0  \n",
      "unknown_13-17      2.0     4.0    12241.0  \n",
      "unknown_18-24      9.0    51.0    44671.0  \n",
      "unknown_25-34     12.0    58.0    31039.0  \n",
      "unknown_35-44     14.0    66.0     8676.0  \n",
      "unknown_45-54     12.0    52.0     7398.0  \n",
      "unknown_55-64     13.0    54.0     4667.0  \n",
      "unknown_65+       17.0    72.0    10228.0  \n",
      "unknown_Unknown    2.0     3.0       27.0  \n"
     ]
    }
   ],
   "source": [
    "# Analyze spend and impressions by demographic group\n",
    "demo_group_stats = demo_df.groupby(\"group\")[[\"spend\", \"impressions\"]].describe()\n",
    "print(\"\\n=== Demographic Distribution: Spend & Impressions ===\")\n",
    "print(demo_group_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf15873-97fa-4e0a-8644-6c21d2f9ff2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count number of ads shown per platform\n",
    "platform_counts = platform_df[\"platform\"].value_counts()\n",
    "print(\"\\n=== Platform Distribution ===\")\n",
    "print(platform_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3a6065-3f55-403f-a4a5-51aaa3730b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count number of ads mentioning each entity/person\n",
    "mentions_counts = mentions_df[\"mention\"].value_counts()\n",
    "print(\"\\n=== Illuminating Mentions Distribution ===\")\n",
    "print(mentions_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8bbd0259-138d-487c-80f6-697dfd697e43",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== FACEBOOK ADS GROUPBY - PANDAS ===\n",
      "Dataset: 246,745 ads, 37 columns\n",
      "Grouping by: page_id (4,475 unique pages)\n",
      "\n",
      "1. TOP 10 PAGES BY TOTAL SPEND\n",
      "============================================================\n",
      "Page ID                                            Ads    Total Spend  Avg Spend \n",
      "--------------------------------------------------------------------------------\n",
      "4d66f5853f0365dba032a87704a634f023d15babde973bb    55503  $82,795,647  $1492     \n",
      "4ade404186269ec62d2dd7d9e0ed5f93a5f32c057516879    14822  $26,367,978  $1779     \n",
      "e3342051b60393770363ffc02946a0f76bc3e4155190d1f    23988  $19,609,362  $817      \n",
      "ec8ac6dc1cddc49972de2c31b62343fe3979729ec437c3b    9851   $10,599,999  $1076     \n",
      "e3ee066f4a12968ba94847059a03c33965ca4eb1ead0f6f    6581   $7,634,469   $1160     \n",
      "330b2f35ded2161e63fbb2b5c5bdae05bff274ff31f990c    10461  $6,135,389   $587      \n",
      "3783ccf18c17765d36f5df639d94a17b6ce3f91f2ec886a    1210   $4,267,040   $3526     \n",
      "66dbd85261d199af2e22a60a56b02e520d2bd66256eb7b6    2203   $4,245,397   $1927     \n",
      "d46be6146feba33b5fd538ae85ded01b0393c7ee2c1e452    1243   $3,267,907   $2629     \n",
      "555285b716dd0e9560ff8c5da4ab27ed5e56d407802ac40    2005   $2,880,145   $1436     \n",
      "\n",
      "2. TOP 10 PAGES BY TOTAL IMPRESSIONS\n",
      "============================================================\n",
      "Page ID                                            Ads    Total Impressions Avg Impressions\n",
      "-------------------------------------------------------------------------------------\n",
      "4d66f5853f0365dba032a87704a634f023d15babde973bb    55503  2,983,465,006   53753       \n",
      "4ade404186269ec62d2dd7d9e0ed5f93a5f32c057516879    14822  841,351,332     56764       \n",
      "e3342051b60393770363ffc02946a0f76bc3e4155190d1f    23988  669,367,149     27904       \n",
      "330b2f35ded2161e63fbb2b5c5bdae05bff274ff31f990c    10461  447,383,598     42767       \n",
      "ec8ac6dc1cddc49972de2c31b62343fe3979729ec437c3b    9851   325,889,696     33082       \n",
      "3783ccf18c17765d36f5df639d94a17b6ce3f91f2ec886a    1210   282,614,901     233566      \n",
      "e3ee066f4a12968ba94847059a03c33965ca4eb1ead0f6f    6581   248,707,946     37792       \n",
      "53a74049e9ff3c4276f15cb0dc6d35c93e830c25a5eee6f    2814   241,507,249     85823       \n",
      "0979f22c3dc6c624cbe0870371231cdb1bc9db78cd13614    838    172,252,713     205552      \n",
      "555285b716dd0e9560ff8c5da4ab27ed5e56d407802ac40    2005   170,650,534     85112       \n",
      "\n",
      "3. TOP 10 PAGES BY AD COUNT\n",
      "============================================================\n",
      "Page ID                                            Ad Count  \n",
      "--------------------------------------------------------------\n",
      "4d66f5853f0365dba032a87704a634f023d15babde973bb    55503     \n",
      "e3342051b60393770363ffc02946a0f76bc3e4155190d1f    23988     \n",
      "4ade404186269ec62d2dd7d9e0ed5f93a5f32c057516879    14822     \n",
      "330b2f35ded2161e63fbb2b5c5bdae05bff274ff31f990c    10461     \n",
      "ec8ac6dc1cddc49972de2c31b62343fe3979729ec437c3b    9851      \n",
      "e3ee066f4a12968ba94847059a03c33965ca4eb1ead0f6f    6581      \n",
      "c5728dbf6f860c0fe9722cb42f5273ec659d701ebf68f3e    3625      \n",
      "19ab0dfc0ac8cd43df84a6ccffad5c3b1972fcfd4453bff    3186      \n",
      "53a74049e9ff3c4276f15cb0dc6d35c93e830c25a5eee6f    2814      \n",
      "8b7ed6251d2f780296c0933fbe3f34ad51046d2d15ecacb    2766      \n",
      "\n",
      "4. TOPIC ANALYSIS BY PAGE\n",
      "============================================================\n",
      "Top 3 pages for economy topic:\n",
      "  4d66f5853f0365dba032a87704a634f023d15bab... : 7351 ads\n",
      "  330b2f35ded2161e63fbb2b5c5bdae05bff274ff... : 2688 ads\n",
      "  4ade404186269ec62d2dd7d9e0ed5f93a5f32c05... : 2020 ads\n",
      "\n",
      "Top 3 pages for health topic:\n",
      "  4d66f5853f0365dba032a87704a634f023d15bab... : 8995 ads\n",
      "  330b2f35ded2161e63fbb2b5c5bdae05bff274ff... : 2743 ads\n",
      "  4ade404186269ec62d2dd7d9e0ed5f93a5f32c05... : 1844 ads\n",
      "\n",
      "5. BYLINES (CAMPAIGN NAMES) ANALYSIS\n",
      "============================================================\n",
      "Pages with most campaign name variations:\n",
      "Page ID                                            Total Ads  Campaign Names \n",
      "-----------------------------------------------------------------------------\n",
      "e3342051b60393770363ffc02946a0f76bc3e4155190d1f    23988      4              \n",
      "315d8edcb37be3f4574cefc76ad0e8661a8824a647353a3    719        3              \n",
      "01b5bff8391f61eb62c6ab94f7dcd62f08698526b177d25    25         3              \n",
      "14710fe93a8c6c4512c86baa53c5713b72e0e74f7be4fc4    2180       3              \n",
      "40ca7faf8cb13dce18a716cfe8ce81f90f09478705d5295    7          3              \n",
      "\n",
      "6. EXECUTION SUMMARY\n",
      "============================================================\n",
      "Pandas execution time: 0.290 seconds\n",
      "Pages analyzed: 4,475\n",
      "Total ads: 246,745\n",
      "Results saved in 'pandas_ads_results' variable\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Facebook Ads Groupby Analysis - Pandas\n",
    "print(\"=== FACEBOOK ADS GROUPBY - PANDAS ===\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Remove complex columns for clean analysis\n",
    "exclude_cols = ['delivery_by_region', 'demographic_distribution', 'publisher_platforms', 'illuminating_mentions']\n",
    "ads_pandas = facebook_ads.drop(columns=[c for c in exclude_cols if c in facebook_ads.columns])\n",
    "\n",
    "print(f\"Dataset: {len(ads_pandas):,} ads, {len(ads_pandas.columns)} columns\")\n",
    "print(f\"Grouping by: page_id ({ads_pandas['page_id'].nunique():,} unique pages)\")\n",
    "\n",
    "print(\"\\n1. TOP 10 PAGES BY TOTAL SPEND\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Group by page_id for spend analysis\n",
    "spend_by_page = ads_pandas.groupby(\"page_id\")['estimated_spend'].agg(['count', 'sum', 'mean']).round(0)\n",
    "spend_by_page.columns = ['ad_count', 'total_spend', 'avg_spend']\n",
    "spend_by_page = spend_by_page.sort_values('total_spend', ascending=False)\n",
    "\n",
    "print(f\"{'Page ID':<50} {'Ads':<6} {'Total Spend':<12} {'Avg Spend':<10}\")\n",
    "print(\"-\" * 80)\n",
    "for page_id, row in spend_by_page.head(10).iterrows():\n",
    "    print(f\"{page_id[:47]:<50} {row['ad_count']:<6.0f} ${row['total_spend']:<11,.0f} ${row['avg_spend']:<9.0f}\")\n",
    "\n",
    "print(\"\\n2. TOP 10 PAGES BY TOTAL IMPRESSIONS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Group by page_id for impressions analysis\n",
    "impressions_by_page = ads_pandas.groupby(\"page_id\")['estimated_impressions'].agg(['count', 'sum', 'mean']).round(0)\n",
    "impressions_by_page.columns = ['ad_count', 'total_impressions', 'avg_impressions']\n",
    "impressions_by_page = impressions_by_page.sort_values('total_impressions', ascending=False)\n",
    "\n",
    "print(f\"{'Page ID':<50} {'Ads':<6} {'Total Impressions':<15} {'Avg Impressions':<12}\")\n",
    "print(\"-\" * 85)\n",
    "for page_id, row in impressions_by_page.head(10).iterrows():\n",
    "    print(f\"{page_id[:47]:<50} {row['ad_count']:<6.0f} {row['total_impressions']:<15,.0f} {row['avg_impressions']:<12.0f}\")\n",
    "\n",
    "print(\"\\n3. TOP 10 PAGES BY AD COUNT\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Group by page_id for ad count\n",
    "ad_count_by_page = ads_pandas.groupby(\"page_id\").size().sort_values(ascending=False)\n",
    "ad_count_by_page.name = 'ad_count'\n",
    "\n",
    "print(f\"{'Page ID':<50} {'Ad Count':<10}\")\n",
    "print(\"-\" * 62)\n",
    "for page_id, ad_count in ad_count_by_page.head(10).items():\n",
    "    print(f\"{page_id[:47]:<50} {ad_count:<10}\")\n",
    "\n",
    "print(\"\\n4. TOPIC ANALYSIS BY PAGE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Economy topic analysis\n",
    "economy_by_page = ads_pandas.groupby(\"page_id\")['economy_topic_illuminating'].sum().sort_values(ascending=False)\n",
    "\n",
    "print(\"Top 3 pages for economy topic:\")\n",
    "for page_id, count in economy_by_page.head(3).items():\n",
    "    print(f\"  {page_id[:40]}... : {count} ads\")\n",
    "\n",
    "# Health topic analysis\n",
    "health_by_page = ads_pandas.groupby(\"page_id\")['health_topic_illuminating'].sum().sort_values(ascending=False)\n",
    "\n",
    "print(\"\\nTop 3 pages for health topic:\")\n",
    "for page_id, count in health_by_page.head(3).items():\n",
    "    print(f\"  {page_id[:40]}... : {count} ads\")\n",
    "\n",
    "print(\"\\n5. BYLINES (CAMPAIGN NAMES) ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Analyze campaign name diversity\n",
    "bylines_stats = ads_pandas.groupby(\"page_id\")['bylines'].agg(['count', 'nunique']).fillna(0)\n",
    "bylines_stats.columns = ['total_ads', 'campaign_names']\n",
    "bylines_stats = bylines_stats.sort_values('campaign_names', ascending=False)\n",
    "\n",
    "print(\"Pages with most campaign name variations:\")\n",
    "print(f\"{'Page ID':<50} {'Total Ads':<10} {'Campaign Names':<15}\")\n",
    "print(\"-\" * 77)\n",
    "for page_id, row in bylines_stats.head(5).iterrows():\n",
    "    print(f\"{page_id[:47]:<50} {row['total_ads']:<10.0f} {row['campaign_names']:<15.0f}\")\n",
    "\n",
    "# Performance timing\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "\n",
    "print(f\"\\n6. EXECUTION SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Pandas execution time: {execution_time:.3f} seconds\")\n",
    "print(f\"Pages analyzed: {ads_pandas['page_id'].nunique():,}\")\n",
    "print(f\"Total ads: {len(ads_pandas):,}\")\n",
    "\n",
    "# Save results for comparison\n",
    "pandas_ads_results = {\n",
    "    'spend_by_page': spend_by_page,\n",
    "    'impressions_by_page': impressions_by_page,\n",
    "    'ad_count_by_page': ad_count_by_page,\n",
    "    'execution_time': execution_time\n",
    "}\n",
    "\n",
    "print(\"Results saved in 'pandas_ads_results' variable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8926e4d6-8c85-4a0b-a253-cebb6a302f17",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== FACEBOOK ADS GROUPBY - PURE PYTHON ===\n",
      "Dataset: 246,745 ads\n",
      "Grouping by: page_id (4,475 unique pages)\n",
      "\n",
      "1. TOP 10 PAGES BY TOTAL SPEND\n",
      "============================================================\n",
      "Page ID                                            Ads    Total Spend  Avg Spend \n",
      "--------------------------------------------------------------------------------\n",
      "4d66f5853f0365dba032a87704a634f023d15babde973bb    55503  $82,795,647  $1492     \n",
      "4ade404186269ec62d2dd7d9e0ed5f93a5f32c057516879    14822  $26,367,978  $1779     \n",
      "e3342051b60393770363ffc02946a0f76bc3e4155190d1f    23988  $19,609,362  $817      \n",
      "ec8ac6dc1cddc49972de2c31b62343fe3979729ec437c3b    9851   $10,599,999  $1076     \n",
      "e3ee066f4a12968ba94847059a03c33965ca4eb1ead0f6f    6581   $7,634,469   $1160     \n",
      "330b2f35ded2161e63fbb2b5c5bdae05bff274ff31f990c    10461  $6,135,389   $587      \n",
      "3783ccf18c17765d36f5df639d94a17b6ce3f91f2ec886a    1210   $4,267,040   $3526     \n",
      "66dbd85261d199af2e22a60a56b02e520d2bd66256eb7b6    2203   $4,245,397   $1927     \n",
      "d46be6146feba33b5fd538ae85ded01b0393c7ee2c1e452    1243   $3,267,907   $2629     \n",
      "555285b716dd0e9560ff8c5da4ab27ed5e56d407802ac40    2005   $2,880,145   $1436     \n",
      "\n",
      "2. TOP 10 PAGES BY TOTAL IMPRESSIONS\n",
      "============================================================\n",
      "Page ID                                            Ads    Total Impressions Avg Impressions\n",
      "-------------------------------------------------------------------------------------\n",
      "4d66f5853f0365dba032a87704a634f023d15babde973bb    55503  2,983,465,006   53753       \n",
      "4ade404186269ec62d2dd7d9e0ed5f93a5f32c057516879    14822  841,351,332     56764       \n",
      "e3342051b60393770363ffc02946a0f76bc3e4155190d1f    23988  669,367,149     27904       \n",
      "330b2f35ded2161e63fbb2b5c5bdae05bff274ff31f990c    10461  447,383,598     42767       \n",
      "ec8ac6dc1cddc49972de2c31b62343fe3979729ec437c3b    9851   325,889,696     33082       \n",
      "3783ccf18c17765d36f5df639d94a17b6ce3f91f2ec886a    1210   282,614,901     233566      \n",
      "e3ee066f4a12968ba94847059a03c33965ca4eb1ead0f6f    6581   248,707,946     37792       \n",
      "53a74049e9ff3c4276f15cb0dc6d35c93e830c25a5eee6f    2814   241,507,249     85823       \n",
      "0979f22c3dc6c624cbe0870371231cdb1bc9db78cd13614    838    172,252,713     205552      \n",
      "555285b716dd0e9560ff8c5da4ab27ed5e56d407802ac40    2005   170,650,534     85112       \n",
      "\n",
      "3. TOP 10 PAGES BY AD COUNT\n",
      "============================================================\n",
      "Page ID                                            Ad Count  \n",
      "--------------------------------------------------------------\n",
      "4d66f5853f0365dba032a87704a634f023d15babde973bb    55503     \n",
      "e3342051b60393770363ffc02946a0f76bc3e4155190d1f    23988     \n",
      "4ade404186269ec62d2dd7d9e0ed5f93a5f32c057516879    14822     \n",
      "330b2f35ded2161e63fbb2b5c5bdae05bff274ff31f990c    10461     \n",
      "ec8ac6dc1cddc49972de2c31b62343fe3979729ec437c3b    9851      \n",
      "e3ee066f4a12968ba94847059a03c33965ca4eb1ead0f6f    6581      \n",
      "c5728dbf6f860c0fe9722cb42f5273ec659d701ebf68f3e    3625      \n",
      "19ab0dfc0ac8cd43df84a6ccffad5c3b1972fcfd4453bff    3186      \n",
      "53a74049e9ff3c4276f15cb0dc6d35c93e830c25a5eee6f    2814      \n",
      "8b7ed6251d2f780296c0933fbe3f34ad51046d2d15ecacb    2766      \n",
      "\n",
      "4. TOPIC ANALYSIS BY PAGE\n",
      "============================================================\n",
      "Top 3 pages for economy topic:\n",
      "  4d66f5853f0365dba032a87704a634f023d15bab... : 7351 ads\n",
      "  330b2f35ded2161e63fbb2b5c5bdae05bff274ff... : 2688 ads\n",
      "  4ade404186269ec62d2dd7d9e0ed5f93a5f32c05... : 2020 ads\n",
      "\n",
      "Top 3 pages for health topic:\n",
      "  4d66f5853f0365dba032a87704a634f023d15bab... : 8995 ads\n",
      "  330b2f35ded2161e63fbb2b5c5bdae05bff274ff... : 2743 ads\n",
      "  4ade404186269ec62d2dd7d9e0ed5f93a5f32c05... : 1844 ads\n",
      "\n",
      "5. BYLINES (CAMPAIGN NAMES) ANALYSIS\n",
      "============================================================\n",
      "Pages with most campaign name variations:\n",
      "Page ID                                            Total Ads  Campaign Names \n",
      "-----------------------------------------------------------------------------\n",
      "e3342051b60393770363ffc02946a0f76bc3e4155190d1f    23988      4              \n",
      "4d66f5853f0365dba032a87704a634f023d15babde973bb    55503      3              \n",
      "14710fe93a8c6c4512c86baa53c5713b72e0e74f7be4fc4    2180       3              \n",
      "315d8edcb37be3f4574cefc76ad0e8661a8824a647353a3    719        3              \n",
      "6f48c6b6927490b8c410a5e12c590ad9a27b8d6733c7d01    496        3              \n",
      "\n",
      "6. EXECUTION SUMMARY\n",
      "============================================================\n",
      "Pure Python execution time: 1.345 seconds\n",
      "Pages analyzed: 4,475\n",
      "Total ads: 246,745\n",
      "Results saved in 'python_ads_results' variable\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from collections import defaultdict\n",
    "\n",
    "# Facebook Ads Groupby Analysis - Pure Python\n",
    "print(\"=== FACEBOOK ADS GROUPBY - PURE PYTHON ===\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Convert to list of dictionaries (exclude complex columns)\n",
    "exclude_cols = ['delivery_by_region', 'demographic_distribution', 'publisher_platforms', 'illuminating_mentions']\n",
    "ads_data = facebook_ads.drop(columns=[c for c in exclude_cols if c in facebook_ads.columns]).to_dict('records')\n",
    "\n",
    "print(f\"Dataset: {len(ads_data):,} ads\")\n",
    "\n",
    "# Manual groupby using dictionaries\n",
    "page_groups = defaultdict(list)\n",
    "for ad in ads_data:\n",
    "    page_id = ad.get('page_id')\n",
    "    if page_id:\n",
    "        page_groups[page_id].append(ad)\n",
    "\n",
    "print(f\"Grouping by: page_id ({len(page_groups):,} unique pages)\")\n",
    "\n",
    "def safe_float(value):\n",
    "    \"\"\"Convert value to float safely\"\"\"\n",
    "    try:\n",
    "        return float(value) if value is not None else 0\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "def calculate_group_stats(ads_list, metric):\n",
    "    \"\"\"Calculate count, sum, mean for a metric across ads\"\"\"\n",
    "    values = [safe_float(ad.get(metric, 0)) for ad in ads_list]\n",
    "    values = [v for v in values if v > 0]  # Remove zeros for meaningful stats\n",
    "    \n",
    "    if not values:\n",
    "        return {'count': 0, 'sum': 0, 'mean': 0}\n",
    "    \n",
    "    return {\n",
    "        'count': len(values),\n",
    "        'sum': sum(values),\n",
    "        'mean': sum(values) / len(values)\n",
    "    }\n",
    "\n",
    "print(\"\\n1. TOP 10 PAGES BY TOTAL SPEND\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Calculate spend stats for each page\n",
    "spend_stats = {}\n",
    "for page_id, ads_list in page_groups.items():\n",
    "    spend_stats[page_id] = calculate_group_stats(ads_list, 'estimated_spend')\n",
    "\n",
    "# Sort by total spend\n",
    "sorted_spend = sorted(spend_stats.items(), key=lambda x: x[1]['sum'], reverse=True)\n",
    "\n",
    "print(f\"{'Page ID':<50} {'Ads':<6} {'Total Spend':<12} {'Avg Spend':<10}\")\n",
    "print(\"-\" * 80)\n",
    "for page_id, stats in sorted_spend[:10]:\n",
    "    print(f\"{page_id[:47]:<50} {stats['count']:<6} ${stats['sum']:<11,.0f} ${stats['mean']:<9.0f}\")\n",
    "\n",
    "print(\"\\n2. TOP 10 PAGES BY TOTAL IMPRESSIONS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Calculate impression stats for each page\n",
    "impression_stats = {}\n",
    "for page_id, ads_list in page_groups.items():\n",
    "    impression_stats[page_id] = calculate_group_stats(ads_list, 'estimated_impressions')\n",
    "\n",
    "# Sort by total impressions\n",
    "sorted_impressions = sorted(impression_stats.items(), key=lambda x: x[1]['sum'], reverse=True)\n",
    "\n",
    "print(f\"{'Page ID':<50} {'Ads':<6} {'Total Impressions':<15} {'Avg Impressions':<12}\")\n",
    "print(\"-\" * 85)\n",
    "for page_id, stats in sorted_impressions[:10]:\n",
    "    print(f\"{page_id[:47]:<50} {stats['count']:<6} {stats['sum']:<15,.0f} {stats['mean']:<12.0f}\")\n",
    "\n",
    "print(\"\\n3. TOP 10 PAGES BY AD COUNT\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Count ads per page\n",
    "ad_counts = {page_id: len(ads_list) for page_id, ads_list in page_groups.items()}\n",
    "sorted_counts = sorted(ad_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(f\"{'Page ID':<50} {'Ad Count':<10}\")\n",
    "print(\"-\" * 62)\n",
    "for page_id, count in sorted_counts[:10]:\n",
    "    print(f\"{page_id[:47]:<50} {count:<10}\")\n",
    "\n",
    "print(\"\\n4. TOPIC ANALYSIS BY PAGE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Economy topic analysis\n",
    "economy_by_page = {}\n",
    "for page_id, ads_list in page_groups.items():\n",
    "    economy_count = sum(safe_float(ad.get('economy_topic_illuminating', 0)) for ad in ads_list)\n",
    "    economy_by_page[page_id] = economy_count\n",
    "\n",
    "sorted_economy = sorted(economy_by_page.items(), key=lambda x: x[1], reverse=True)\n",
    "print(\"Top 3 pages for economy topic:\")\n",
    "for page_id, count in sorted_economy[:3]:\n",
    "    print(f\"  {page_id[:40]}... : {count:.0f} ads\")\n",
    "\n",
    "# Health topic analysis\n",
    "health_by_page = {}\n",
    "for page_id, ads_list in page_groups.items():\n",
    "    health_count = sum(safe_float(ad.get('health_topic_illuminating', 0)) for ad in ads_list)\n",
    "    health_by_page[page_id] = health_count\n",
    "\n",
    "sorted_health = sorted(health_by_page.items(), key=lambda x: x[1], reverse=True)\n",
    "print(\"\\nTop 3 pages for health topic:\")\n",
    "for page_id, count in sorted_health[:3]:\n",
    "    print(f\"  {page_id[:40]}... : {count:.0f} ads\")\n",
    "\n",
    "print(\"\\n5. BYLINES (CAMPAIGN NAMES) ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Analyze campaign name diversity\n",
    "bylines_stats = {}\n",
    "for page_id, ads_list in page_groups.items():\n",
    "    bylines = [ad.get('bylines') for ad in ads_list if ad.get('bylines')]\n",
    "    unique_bylines = set(bylines) if bylines else set()\n",
    "    \n",
    "    bylines_stats[page_id] = {\n",
    "        'total_ads': len(ads_list),\n",
    "        'campaign_names': len(unique_bylines)\n",
    "    }\n",
    "\n",
    "# Sort by campaign name diversity\n",
    "sorted_bylines = sorted(bylines_stats.items(), key=lambda x: x[1]['campaign_names'], reverse=True)\n",
    "\n",
    "print(\"Pages with most campaign name variations:\")\n",
    "print(f\"{'Page ID':<50} {'Total Ads':<10} {'Campaign Names':<15}\")\n",
    "print(\"-\" * 77)\n",
    "for page_id, stats in sorted_bylines[:5]:\n",
    "    print(f\"{page_id[:47]:<50} {stats['total_ads']:<10} {stats['campaign_names']:<15}\")\n",
    "\n",
    "# Performance timing\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "\n",
    "print(f\"\\n6. EXECUTION SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Pure Python execution time: {execution_time:.3f} seconds\")\n",
    "print(f\"Pages analyzed: {len(page_groups):,}\")\n",
    "print(f\"Total ads: {len(ads_data):,}\")\n",
    "\n",
    "# Save results for comparison\n",
    "python_ads_results = {\n",
    "    'spend_stats': dict(sorted_spend),\n",
    "    'impression_stats': dict(sorted_impressions),\n",
    "    'ad_counts': dict(sorted_counts),\n",
    "    'execution_time': execution_time\n",
    "}\n",
    "\n",
    "print(\"Results saved in 'python_ads_results' variable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "534b6924-2474-40de-9c3a-7d10767a7967",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== FACEBOOK ADS GROUPBY - POLARS ===\n",
      "Successfully converted to Polars DataFrame\n",
      "Dataset: 246,745 ads, 37 columns\n",
      "Grouping by: page_id (4,475 unique pages)\n",
      "\n",
      "1. TOP 10 PAGES BY TOTAL SPEND\n",
      "============================================================\n",
      "Page ID                                            Ads    Total Spend  Avg Spend \n",
      "--------------------------------------------------------------------------------\n",
      "4d66f5853f0365dba032a87704a634f023d15babde973bb    55503  $82,795,647  $1492     \n",
      "4ade404186269ec62d2dd7d9e0ed5f93a5f32c057516879    14822  $26,367,978  $1779     \n",
      "e3342051b60393770363ffc02946a0f76bc3e4155190d1f    23988  $19,609,362  $817      \n",
      "ec8ac6dc1cddc49972de2c31b62343fe3979729ec437c3b    9851   $10,599,999  $1076     \n",
      "e3ee066f4a12968ba94847059a03c33965ca4eb1ead0f6f    6581   $7,634,469   $1160     \n",
      "330b2f35ded2161e63fbb2b5c5bdae05bff274ff31f990c    10461  $6,135,389   $587      \n",
      "3783ccf18c17765d36f5df639d94a17b6ce3f91f2ec886a    1210   $4,267,040   $3526     \n",
      "66dbd85261d199af2e22a60a56b02e520d2bd66256eb7b6    2203   $4,245,397   $1927     \n",
      "d46be6146feba33b5fd538ae85ded01b0393c7ee2c1e452    1243   $3,267,907   $2629     \n",
      "555285b716dd0e9560ff8c5da4ab27ed5e56d407802ac40    2005   $2,880,145   $1436     \n",
      "\n",
      "2. TOP 10 PAGES BY TOTAL IMPRESSIONS\n",
      "============================================================\n",
      "Page ID                                            Ads    Total Impressions Avg Impressions\n",
      "-------------------------------------------------------------------------------------\n",
      "4d66f5853f0365dba032a87704a634f023d15babde973bb    55503  2,983,465,006   53753       \n",
      "4ade404186269ec62d2dd7d9e0ed5f93a5f32c057516879    14822  841,351,332     56764       \n",
      "e3342051b60393770363ffc02946a0f76bc3e4155190d1f    23988  669,367,149     27904       \n",
      "330b2f35ded2161e63fbb2b5c5bdae05bff274ff31f990c    10461  447,383,598     42767       \n",
      "ec8ac6dc1cddc49972de2c31b62343fe3979729ec437c3b    9851   325,889,696     33082       \n",
      "3783ccf18c17765d36f5df639d94a17b6ce3f91f2ec886a    1210   282,614,901     233566      \n",
      "e3ee066f4a12968ba94847059a03c33965ca4eb1ead0f6f    6581   248,707,946     37792       \n",
      "53a74049e9ff3c4276f15cb0dc6d35c93e830c25a5eee6f    2814   241,507,249     85823       \n",
      "0979f22c3dc6c624cbe0870371231cdb1bc9db78cd13614    838    172,252,713     205552      \n",
      "555285b716dd0e9560ff8c5da4ab27ed5e56d407802ac40    2005   170,650,534     85112       \n",
      "\n",
      "3. TOP 10 PAGES BY AD COUNT\n",
      "============================================================\n",
      "Page ID                                            Ad Count  \n",
      "--------------------------------------------------------------\n",
      "4d66f5853f0365dba032a87704a634f023d15babde973bb    55503     \n",
      "e3342051b60393770363ffc02946a0f76bc3e4155190d1f    23988     \n",
      "4ade404186269ec62d2dd7d9e0ed5f93a5f32c057516879    14822     \n",
      "330b2f35ded2161e63fbb2b5c5bdae05bff274ff31f990c    10461     \n",
      "ec8ac6dc1cddc49972de2c31b62343fe3979729ec437c3b    9851      \n",
      "e3ee066f4a12968ba94847059a03c33965ca4eb1ead0f6f    6581      \n",
      "c5728dbf6f860c0fe9722cb42f5273ec659d701ebf68f3e    3625      \n",
      "19ab0dfc0ac8cd43df84a6ccffad5c3b1972fcfd4453bff    3186      \n",
      "53a74049e9ff3c4276f15cb0dc6d35c93e830c25a5eee6f    2814      \n",
      "8b7ed6251d2f780296c0933fbe3f34ad51046d2d15ecacb    2766      \n",
      "\n",
      "4. TOPIC ANALYSIS BY PAGE\n",
      "============================================================\n",
      "Top 3 pages for economy topic:\n",
      "  4d66f5853f0365dba032a87704a634f023d15bab... : 7351 ads\n",
      "  330b2f35ded2161e63fbb2b5c5bdae05bff274ff... : 2688 ads\n",
      "  4ade404186269ec62d2dd7d9e0ed5f93a5f32c05... : 2020 ads\n",
      "\n",
      "Top 3 pages for health topic:\n",
      "  4d66f5853f0365dba032a87704a634f023d15bab... : 8995 ads\n",
      "  330b2f35ded2161e63fbb2b5c5bdae05bff274ff... : 2743 ads\n",
      "  4ade404186269ec62d2dd7d9e0ed5f93a5f32c05... : 1844 ads\n",
      "\n",
      "5. BYLINES (CAMPAIGN NAMES) ANALYSIS\n",
      "============================================================\n",
      "Pages with most campaign name variations:\n",
      "Page ID                                            Total Ads  Campaign Names \n",
      "-----------------------------------------------------------------------------\n",
      "e3342051b60393770363ffc02946a0f76bc3e4155190d1f    23988      4              \n",
      "c0e307c7078a42b180f148853832befdf6ef139dc201654    86         3              \n",
      "6f48c6b6927490b8c410a5e12c590ad9a27b8d6733c7d01    496        3              \n",
      "4d66f5853f0365dba032a87704a634f023d15babde973bb    55503      3              \n",
      "4ade404186269ec62d2dd7d9e0ed5f93a5f32c057516879    14822      3              \n",
      "\n",
      "6. EXECUTION SUMMARY\n",
      "============================================================\n",
      "Polars execution time: 0.250 seconds\n",
      "Pages analyzed: 4,475\n",
      "Total ads: 246,745\n",
      "Results saved in 'polars_ads_results' variable\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "import time\n",
    "\n",
    "# Facebook Ads Groupby Analysis - Polars\n",
    "print(\"=== FACEBOOK ADS GROUPBY - POLARS ===\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Convert pandas DataFrame to Polars and remove complex columns\n",
    "exclude_cols = ['delivery_by_region', 'demographic_distribution', 'publisher_platforms', 'illuminating_mentions']\n",
    "ads_clean_df = facebook_ads.drop(columns=[c for c in exclude_cols if c in facebook_ads.columns])\n",
    "\n",
    "# Convert to Polars\n",
    "try:\n",
    "    ads_polars = pl.from_pandas(ads_clean_df)\n",
    "    print(\"Successfully converted to Polars DataFrame\")\n",
    "except Exception as e:\n",
    "    print(f\"Conversion error: {e}\")\n",
    "    print(\"Using alternative method...\")\n",
    "    # Alternative: save to CSV and reload with Polars\n",
    "    ads_clean_df.to_csv('temp_ads.csv', index=False)\n",
    "    ads_polars = pl.read_csv('temp_ads.csv')\n",
    "\n",
    "print(f\"Dataset: {ads_polars.height:,} ads, {len(ads_polars.columns)} columns\")\n",
    "print(f\"Grouping by: page_id ({ads_polars.select('page_id').n_unique():,} unique pages)\")\n",
    "\n",
    "print(\"\\n1. TOP 10 PAGES BY TOTAL SPEND\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Group by page_id for spend analysis\n",
    "spend_by_page = ads_polars.group_by(\"page_id\").agg([\n",
    "    pl.col('estimated_spend').count().alias('ad_count'),\n",
    "    pl.col('estimated_spend').sum().alias('total_spend'),\n",
    "    pl.col('estimated_spend').mean().alias('avg_spend')\n",
    "]).sort('total_spend', descending=True)\n",
    "\n",
    "print(f\"{'Page ID':<50} {'Ads':<6} {'Total Spend':<12} {'Avg Spend':<10}\")\n",
    "print(\"-\" * 80)\n",
    "for i in range(min(10, spend_by_page.height)):\n",
    "    page_id = spend_by_page.item(i, 'page_id')\n",
    "    ad_count = spend_by_page.item(i, 'ad_count')\n",
    "    total_spend = spend_by_page.item(i, 'total_spend')\n",
    "    avg_spend = spend_by_page.item(i, 'avg_spend')\n",
    "    \n",
    "    print(f\"{page_id[:47]:<50} {ad_count:<6} ${total_spend:<11,.0f} ${avg_spend:<9.0f}\")\n",
    "\n",
    "print(\"\\n2. TOP 10 PAGES BY TOTAL IMPRESSIONS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Group by page_id for impressions analysis\n",
    "impressions_by_page = ads_polars.group_by(\"page_id\").agg([\n",
    "    pl.col('estimated_impressions').count().alias('ad_count'),\n",
    "    pl.col('estimated_impressions').sum().alias('total_impressions'),\n",
    "    pl.col('estimated_impressions').mean().alias('avg_impressions')\n",
    "]).sort('total_impressions', descending=True)\n",
    "\n",
    "print(f\"{'Page ID':<50} {'Ads':<6} {'Total Impressions':<15} {'Avg Impressions':<12}\")\n",
    "print(\"-\" * 85)\n",
    "for i in range(min(10, impressions_by_page.height)):\n",
    "    page_id = impressions_by_page.item(i, 'page_id')\n",
    "    ad_count = impressions_by_page.item(i, 'ad_count')\n",
    "    total_impressions = impressions_by_page.item(i, 'total_impressions')\n",
    "    avg_impressions = impressions_by_page.item(i, 'avg_impressions')\n",
    "    \n",
    "    print(f\"{page_id[:47]:<50} {ad_count:<6} {total_impressions:<15,.0f} {avg_impressions:<12.0f}\")\n",
    "\n",
    "print(\"\\n3. TOP 10 PAGES BY AD COUNT\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Group by page_id for ad count\n",
    "ad_count_by_page = ads_polars.group_by(\"page_id\").agg([\n",
    "    pl.len().alias('ad_count')\n",
    "]).sort('ad_count', descending=True)\n",
    "\n",
    "print(f\"{'Page ID':<50} {'Ad Count':<10}\")\n",
    "print(\"-\" * 62)\n",
    "for i in range(min(10, ad_count_by_page.height)):\n",
    "    page_id = ad_count_by_page.item(i, 'page_id')\n",
    "    ad_count = ad_count_by_page.item(i, 'ad_count')\n",
    "    print(f\"{page_id[:47]:<50} {ad_count:<10}\")\n",
    "\n",
    "print(\"\\n4. TOPIC ANALYSIS BY PAGE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Economy topic analysis\n",
    "economy_by_page = ads_polars.group_by(\"page_id\").agg([\n",
    "    pl.col('economy_topic_illuminating').sum().alias('economy_ads')\n",
    "]).sort('economy_ads', descending=True)\n",
    "\n",
    "print(\"Top 3 pages for economy topic:\")\n",
    "for i in range(min(3, economy_by_page.height)):\n",
    "    page_id = economy_by_page.item(i, 'page_id')\n",
    "    count = economy_by_page.item(i, 'economy_ads')\n",
    "    print(f\"  {page_id[:40]}... : {count} ads\")\n",
    "\n",
    "# Health topic analysis\n",
    "health_by_page = ads_polars.group_by(\"page_id\").agg([\n",
    "    pl.col('health_topic_illuminating').sum().alias('health_ads')\n",
    "]).sort('health_ads', descending=True)\n",
    "\n",
    "print(\"\\nTop 3 pages for health topic:\")\n",
    "for i in range(min(3, health_by_page.height)):\n",
    "    page_id = health_by_page.item(i, 'page_id')\n",
    "    count = health_by_page.item(i, 'health_ads')\n",
    "    print(f\"  {page_id[:40]}... : {count} ads\")\n",
    "\n",
    "print(\"\\n5. BYLINES (CAMPAIGN NAMES) ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Analyze campaign name diversity\n",
    "bylines_stats = ads_polars.group_by(\"page_id\").agg([\n",
    "    pl.len().alias('total_ads'),\n",
    "    pl.col('bylines').n_unique().alias('campaign_names')\n",
    "]).sort('campaign_names', descending=True)\n",
    "\n",
    "print(\"Pages with most campaign name variations:\")\n",
    "print(f\"{'Page ID':<50} {'Total Ads':<10} {'Campaign Names':<15}\")\n",
    "print(\"-\" * 77)\n",
    "for i in range(min(5, bylines_stats.height)):\n",
    "    page_id = bylines_stats.item(i, 'page_id')\n",
    "    total_ads = bylines_stats.item(i, 'total_ads')\n",
    "    campaign_names = bylines_stats.item(i, 'campaign_names')\n",
    "    print(f\"{page_id[:47]:<50} {total_ads:<10} {campaign_names:<15}\")\n",
    "\n",
    "# Performance timing\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "\n",
    "print(f\"\\n6. EXECUTION SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Polars execution time: {execution_time:.3f} seconds\")\n",
    "print(f\"Pages analyzed: {ads_polars.select('page_id').n_unique():,}\")\n",
    "print(f\"Total ads: {ads_polars.height:,}\")\n",
    "\n",
    "# Save results for comparison\n",
    "polars_ads_results = {\n",
    "    'spend_by_page': spend_by_page,\n",
    "    'impressions_by_page': impressions_by_page,\n",
    "    'ad_count_by_page': ad_count_by_page,\n",
    "    'execution_time': execution_time\n",
    "}\n",
    "\n",
    "print(\"Results saved in 'polars_ads_results' variable\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bba438a-39c6-4ca7-b874-aec4cb0da58b",
   "metadata": {},
   "source": [
    "## My Comparison: Polars vs. Pandas vs. Pure Python GroupBy**\n",
    "\n",
    "**1. What I Did and Why**\n",
    "\n",
    "I wanted to analyze my Facebook Ads data by page (page_id) to answer questions like:\n",
    "\n",
    "Which pages spent the most?\n",
    "\n",
    "Which pages got the most impressions?\n",
    "\n",
    "Which pages ran the most ads?\n",
    "\n",
    "To be thorough, I did this using three different approaches: Polars, Pandas, and pure Python, so I could compare speed, convenience, and results.\n",
    "\n",
    "2. What I Found\n",
    "All three methods gave me the same answers for the big questions (top pages by spend, impressions, ad count, top topics, and campaign name diversity).\n",
    "\n",
    "Polars was the fastest—done in about 0.25 seconds!\n",
    "\n",
    "Pandas was also quick and is easy to use for most data analysis tasks.\n",
    "\n",
    "Pure Python worked, but was much slower and would be a pain with huge datasets.\n",
    "\n",
    "3. Why I Handled Complex Columns Separately\n",
    "Some columns—like delivery_by_region, demographic_distribution, and illuminating_mentions—aren’t simple numbers or labels. They’re actually lists or dictionaries inside each row.\n",
    "\n",
    "I didn’t include these in my main groupby summaries (like mean, sum, etc.) because they don’t make sense for those calculations. If I did, I’d get unreadable outputs (huge blobs of text or JSON).\n",
    "\n",
    "Instead, I unpacked or exploded these columns and analyzed them one at a time. For example:\n",
    "\n",
    "I might count how many times a candidate was mentioned across all ads.\n",
    "\n",
    "Or I could summarize spend by state if the region info is nested.\n",
    "\n",
    "This kept my groupby tables clear, focused, and readable.\n",
    "\n",
    "4. Why I Took This Approach\n",
    "I grouped straightforward columns together for classic stats and rankings.\n",
    "\n",
    "For the complex or nested columns, I wrote special logic to get real insights, not just noise.\n",
    "\n",
    "5. Which Tool Would I Use (and Why)?\n",
    "For very large datasets, I’d choose Polars—it’s lightning fast.\n",
    "\n",
    "For most analysis tasks, I’d go with Pandas for its power and ease of use.\n",
    "\n",
    "I’d only use pure Python if I absolutely had to (e.g., no external packages allowed).\n",
    "\n",
    "Summary\n",
    "I used three different tools to make sure my results were consistent and reliable.\n",
    "I analyzed complex/nested columns separately so my groupby stats stayed clear and actionable.\n",
    "This approach kept my analysis fast, tidy, and actually useful.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5fa926-9eb0-41a4-a8e9-919d8066eb66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
